@article{Cleland-Huang2010,
abstract = {Regulatory standards, designed to protect the safety, security, and privacy of the public, govern numerous areas of software intensive systems. Project personnel must therefore demonstrate that an as-built system meets all relevant regulatory codes. Current methods for demonstrating compliance rely either on after-the-fact audits, which can lead to significant refactoring when regulations are not met, or else require analysts to construct and use traceability matrices to demonstrate compliance. Manual tracing can be prohibitively time-consuming; however automated trace retrieval methods are not very effective due to the vocabulary mismatches that often occur between regulatory codes and product level requirements. This paper introduces and evaluates two machine-learning methods, designed to improve the quality of traces generated between regulatory codes and product level requirements. The first approach uses manually created traceability matrices to train a trace classifier, while the second approach uses web-mining techniques to reconstruct the original trace query. The techniques were evaluated against security regulations from the USA government's Health Insurance Privacy and Portability Act (HIPAA) traced against ten healthcare related requirements specifications. Results demonstrated improvements for the subset of HIPAA regulations that exhibited high fan-out behavior across the requirements datasets.},
author = {Cleland-Huang, Jane and Czauderna, Adam and Gibiec, Marek and Emenecker, John},
doi = {10.1145/1806799.1806825},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AMachineLearningApproachForTracingRegulatoryCodesToProductSpecificRequirements.pdf:pdf},
isbn = {9781605587196},
issn = {0270-5257},
journal = {Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - ICSE '10},
keywords = {[Electronic Manuscript],regulatory compliance,requirements classification,traceability},
pages = {155},
title = {{A machine learning approach for tracing regulatory codes to product specific requirements}},
url = {http://portal.acm.org/citation.cfm?doid=1806799.1806825},
volume = {1},
year = {2010}
}
@book{sutton1998reinforcement,
author = {Sutton, Richard S and Barto, Andrew G and Others},
publisher = {MIT press},
title = {{Reinforcement learning: An introduction}},
year = {1998}
}
@inproceedings{yang2012speculative,
author = {Yang, Hui and {De Roeck}, Anne and Gervasi, Vincenzo and Willis, Alistair and Nuseibeh, Bashar},
booktitle = {Requirements Engineering Conference (RE), 2012 20th IEEE International},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/SpeculativeRequirementsAutomaticDetectionOfUncertaintyInNaturalLanguageRequirements.pdf:pdf},
organization = {IEEE},
pages = {11--20},
title = {{Speculative requirements: Automatic detection of uncertainty in natural language requirements}},
year = {2012}
}
@article{samuel1959some,
author = {Samuel, Arthur L},
journal = {IBM Journal of research and development},
number = {3},
pages = {210--229},
publisher = {IBM},
title = {{Some studies in machine learning using the game of checkers}},
volume = {3},
year = {1959}
}
@techreport{collobert2002torch,
abstract = {Many scientific communities have expressed a growing interest in machine learning algorithms recently, mainly due to the generally good results they provide, compared to traditional statistical or AI approaches. However, these machine learning algorithms are often complex to implement and to use properly and efficiently. We thus present in this paper a new machine learning software library in which most state-of-the-art algorithms have already been implemented and are available in a unified framework, in order for scientists to be able to use them, compare them, and even extend them. More interestingly, this library is freely available under a BSD license and can be retrieved on the web by everyone.},
author = {Collobert, Ronan and Bengio, Samy and Mariethoz, Johnny and Mari{\'{e}}thoz, Johnny},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/TorchAModularMachineLearningSoftwareLibrary.pdf:pdf},
institution = {Idiap},
isbn = {IDIAP-RR 02-46},
pages = {7},
title = {{Torch: a modular machine learning software library}},
year = {2002}
}
@inproceedings{sharma2014automated,
author = {Sharma, Richa and Bhatia, Jaspreet and Biswas, Kanad K},
booktitle = {Advance Computing Conference (IACC), 2014 IEEE International},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AutomatedIdentificationOfBusenessRulesInRequirementsDocuments.pdf:pdf},
organization = {IEEE},
pages = {1442--1447},
title = {{Automated identification of business rules in requirements documents}},
year = {2014}
}
@inproceedings{li2017identifying,
author = {Li, Tong},
booktitle = {Asia-Pacific Software Engineering Conference (APSEC), 2017 24th},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/IdentifyingSecurityRequirementsBasedOnLinguisticAnalysisAndMachineearning.pdf:pdf},
organization = {IEEE},
pages = {388--397},
title = {{Identifying Security Requirements Based on Linguistic Analysis and Machine Learning}},
year = {2017}
}
@article{dargan2016systems,
author = {Dargan, John L. and Wasek, James S. and Campos-Nanez, Enrique},
doi = {10.1007/s00766-015-0232-4},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/SystemsPerformancePredictionUsingRequirementsQualityAtrributesClassification.pdf:pdf},
issn = {1432010X},
journal = {Requirements Engineering},
keywords = {Natural language requirements,Poor requirements,Requirements definition,Requirements engineering,Requirements quality attributes},
number = {4},
pages = {553--572},
publisher = {Springer},
title = {{Systems performance prediction using requirements quality attributes classification}},
volume = {21},
year = {2016}
}
@book{thayer1997software,
author = {Thayer, Richard H and Bailin, Sidney C and Dorfman, M},
publisher = {IEEE Computer Society Press},
title = {{Software requirements engineerings}},
year = {1997}
}
@article{Mills2017,
abstract = {Traceability Link Recovery (TLR) is a fundamental software maintenance task in which links are established between related software artifacts of different types (e.g., source code, documentation, requirements specifications, etc.) within a system. Existing approaches to TLR often require a human to analyze a long list of potential links and distinguish valid links from invalid ones. Here we present an approach which bypasses this intermediate step and automatically classifies links as valid or invalid using a machine learning approach and features such as text retrieval (TR) rankings and query quality (QQ) metrics. We performed an evaluation on recovering traceability links in three software systems and the results show the potential of our approach, which achieved 95{\%} accuracy on average using both types of features.},
author = {Mills, Chris and Haiduc, Sonia},
doi = {10.1109/ICSE-C.2017.86},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AMachineLearningApproachForDeterminingTheValidityOfTraceabilityLinks.pdf:pdf},
isbn = {9781538615898},
journal = {Proceedings - 2017 IEEE/ACM 39th International Conference on Software Engineering Companion, ICSE-C 2017},
keywords = {Classification,Supervised machine learning,Text retrieval,Traceability},
pages = {121--123},
title = {{A machine learning approach for determining the validity of traceability links}},
year = {2017}
}
@misc{kotsiantis2007supervised,
author = {Kotsiantis, Sotiris B and Zaharakis, I and Pintelas, P},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/SupervisedMachineLearningAReviewOfClassificationTechniquespdf.pdf:pdf},
title = {{Supervised machine learning: A review of classification techniques}},
year = {2007}
}
@article{Slankas2013,
author = {Slankas, John and Williams, Laurie},
doi = {10.1109/NAturaLiSE.2013.6611715},
isbn = {9781467362719},
journal = {2013 1st International Workshop on Natural Language Analysis in Software Engineering, NaturaLiSE 2013 - Proceedings},
keywords = {classification,documentation,machine learning,natural language processing,non-functional requirements},
pages = {9--16},
title = {{Automated extraction of non-functional requirements in available documentation}},
year = {2013}
}
@article{Nuseibeh,
abstract = {This paper presents an overview of the field of software systems requirements engineering (RE). It describes the main areas of RE practice, and highlights some key open research issues for the future.},
archivePrefix = {arXiv},
arxivId = {1003.1141},
author = {Nuseibeh, Bashar and Easterbrook, Steve},
doi = {10.1145/336512.336523},
eprint = {1003.1141},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/RequiremnestEngineeringARoadMap.pdf:pdf},
isbn = {1581132530},
issn = {00368075},
pmid = {17742320},
title = {{Requirements Engineering: A Roadmap}}
}
@article{Sardinha2013,
abstract = {One of the aims of aspect-oriented requirements engineering is to address the composability and subsequent analysis of crosscutting and non-crosscutting concerns during requirements engineering. Composing concerns may help to reveal conflicting dependencies that need to be identified and resolved. However, detecting conflicts in a large set of textual aspect-oriented requirements is an error-prone and time-consuming task. This paper presents EA-analyzer, the first automated tool for identifying conflicts in aspect-oriented requirements specified in natural-language text. The tool is based on a novel application of a Bayesian learning method that has been effective at classifying text. We present an empirical evaluation of the tool with three industrial-strength requirements documents from different real-life domains. We show that the tool achieves up to 92.97{\%} accuracy when one of the case study documents is used as a training set and the other two as a validation set.},
author = {Sardinha, Alberto and Chitchyan, Ruzanna and Weston, Nathan and Greenwood, Phil and Rashid, Awais},
doi = {10.1007/s10515-012-0106-7},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/EA-AnalyzerAutomatingConflictDetectioniInALargeSetOfTextualAspectOrientedRequirements.pdf:pdf},
isbn = {9780769538914},
issn = {09288910},
journal = {Automated Software Engineering},
number = {1},
pages = {111--135},
title = {{EA-Analyzer: Automating conflict detection in a large set of textual aspect-oriented requirements}},
volume = {20},
year = {2013}
}
@article{fitzgerald2012early,
author = {Fitzgerald, Camilo and Letier, Emmanuel and Finkelstein, Anthony},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/EarlyFailurePredictionInFeatureRequestManagementSystemsAnExtendedStudy.pdf:pdf},
journal = {Requirements Engineering},
number = {2},
pages = {117--132},
publisher = {Springer},
title = {{Early failure prediction in feature request management systems: an extended study}},
volume = {17},
year = {2012}
}
@inproceedings{dekhtyar2017re,
author = {Dekhtyar, Alex and Fong, Vivian},
booktitle = {Requirements Engineering Conference (RE), 2017 IEEE 25th International},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/REDataChallengeRequirementsIdentificationWithWord2VecAndTensorFlow.pdf:pdf},
organization = {IEEE},
pages = {484--489},
title = {{RE Data Challenge: Requirements Identification with Word2Vec and TensorFlow}},
year = {2017}
}
@conference{Jindal20162027,
abstract = {Requirement engineers are not able to elicit and analyze the security requirements clearly, that are essential for the development of secure and reliable software. Proper identification of security requirements present in the Software Requirement Specification (SRS) document has been a problem being faced by the developers. As a result, they are not able to deliver the software free from threats and vulnerabilities. Thus, in this paper, we intend to mine the descriptions of security requirements present in the SRS document and thereafter develop the classification models. The security-based descriptions are analyzed using text mining techniques and are then classified into four types of security requirements viz. authentication-authorization, access control, cryptography-encryption and data integrity using J48 decision tree method. Corresponding to each type of security requirement, a prediction model has been developed. The effectiveness of the prediction models is evaluated against requirement specifications collected from 15 projects which have been developed by MS students at DePaul University. The result analysis indicated that all the four models have performed very well in predicting their respective type of security requirements. {\textcopyright} 2016 IEEE.},
annote = {cited By 2},
author = {Jindal, R and Malhotra, R and Jain, A},
booktitle = {2016 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2016},
doi = {10.1109/ICACCI.2016.7732349},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AutomatedClassificationOfSecurityRequirements.pdf:pdf},
pages = {2027--2033},
title = {{Automated classification of security requirements}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85007400793{\&}doi=10.1109{\%}2FICACCI.2016.7732349{\&}partnerID=40{\&}md5=8d3c3ef8a9259f52267b7d3637f9879f},
year = {2016}
}
@article{del2017stability,
author = {del Sagrado, Jos{\'{e}} and del {\'{A}}guila, Isabel M.},
doi = {10.1007/s11219-017-9362-x},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/StabilityPredictionOfTheSoftwareRequirementsSpecification.pdf:pdf},
issn = {15731367},
journal = {Software Quality Journal},
keywords = {Bayesian network,CASE tools,Requirements engineering,Software requirements specification},
number = {2},
pages = {585--605},
publisher = {Springer},
title = {{Stability prediction of the software requirements specification}},
volume = {26},
year = {2018}
}
@article{kurtanovic2017automatically,
abstract = {In this paper, we take up the second RE17 data challenge: the identification of requirements types using the ”Quality attributes (NFR)” dataset provided.We studied how ac- curately we can automatically classify requirements as functional (FR) and non-functional (NFR) in the dataset with supervised machine learning. Furthermore, we assessed how accurately we can identify various types of NFRs, in particular usability, security, operational, and performance requirements. We developed and evaluated a supervised machine learning approach employing meta-data, lexical, and syntactical features. We employed under- and over-sampling strategies to handle the imbalanced classes in the dataset and cross-validated the classifiers using precision, recall, and F1 metrics in a series of experiments based on the Support Vector Machine classifier algorithm. We achieve a precision and recall up to {\~{}}92{\%} for automatically identifying FRs and NFRs. For the identification of specific NFRs, we achieve the highest precision and recall for security and performance NFRs with {\~{}}92{\%} precision and {\~{}}90{\%} recall. We discuss the most discriminating features of FRs and NFRs as well as the sampling strategies used with an additional dataset and their impact on the classification accuracy.},
author = {Kurtanovic, Zijad and Maalej, Walid},
doi = {10.1109/RE.2017.82},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AutomaticallyClassifyingFunctionalAndNonFunctionalRequirementsUsingSupervisedMachineLearning.pdf:pdf},
institution = {IEEE},
isbn = {978-1-5386-3191-1},
journal = {2017 IEEE 25th International Requirements Engineering Conference (RE)},
pages = {490--495},
title = {{Automatically Classifying Functional and Non-functional Requirements Using Supervised Machine Learning}},
url = {http://ieeexplore.ieee.org/document/8049171/},
year = {2017}
}
@article{Parra2015180,
abstract = {Context One of the most important factors in the development of a software project is the quality of their requirements. Erroneous requirements, if not detected early, may cause many serious problems, such as substantial additional costs, failure to meet the expected objectives and delays in delivery dates. For these reasons, great effort must be devoted in requirements engineering to ensure that the project's requirements results are of high quality. One of the aims of this discipline is the automatic processing of requirements for assessing their quality; this aim, however, results in a complex task because the quality of requirements depends mostly on the interpretation of experts and the necessities and demands of the project at hand. Objective The objective of this paper is to assess the quality of requirements automatically, emulating the assessment that a quality expert of a project would assess. Method The proposed methodology is based on the idea of learning based on standard metrics that represent the characteristics that an expert takes into consideration when deciding on the good or bad quality of requirements. Using machine learning techniques, a classifier is trained with requirements earlier classified by the expert, which then is used for classifying newly provided requirements. Results We present two approaches to represent the methodology with two situations of the problem in function of the requirement corpus learning balancing, obtaining different results in the accuracy and the efficiency in order to evaluate both representations. The paper demonstrates the reliability of the methodology by presenting a case study with requirements provided by the Requirements Working Group of the INCOSE organization. Conclusions A methodology that evaluates the quality of requirements written in natural language is presented in order to emulate the quality that the expert would provide for new requirements, with 86.1 of average in the accuracy. {\textcopyright} 2015 Elsevier B.V.},
annote = {cited By 3},
author = {Parra, E and Dimou, C and Llorens, J and Moreno, V and Fraga, A},
doi = {10.1016/j.infsof.2015.07.006},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AMethodologyForTheClassificationOfQualityOfRequirementsUsingMachineLearningTechniques.pdf:pdf},
journal = {Information and Software Technology},
pages = {180--195},
title = {{A methodology for the classification of quality of requirements using machine learning techniques}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84942019840{\&}doi=10.1016{\%}2Fj.infsof.2015.07.006{\&}partnerID=40{\&}md5=0cb84f8e97c794f55a9c78c45a0dd2f1},
volume = {67},
year = {2015}
}
@inproceedings{yang2010extending,
author = {Yang, Hui and {De Roeck}, Anne and Gervasi, Vincenzo and Willis, Alistair and Nuseibeh, Bashar},
booktitle = {Requirements Engineering Conference (RE), 2010 18th IEEE International},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/ExtendingNocuousAmbiguityAnalysisForAnaphoraInNaturalLanguageRequirements.pdf:pdf},
organization = {IEEE},
pages = {25--34},
title = {{Extending nocuous ambiguity analysis for anaphora in natural language requirements}},
year = {2010}
}
@article{Yang2011,
abstract = {Many requirements documents are written in natural language (NL). However, with the flexibility of NL comes the risk of introducing unwanted ambiguities in the requirements and misunderstandings between stakeholders. In this paper, we describe an automated approach to identify potentially nocuous ambiguity, which occurs when text is interpreted differently by different readers. We concentrate on anaphoric ambiguity, which occurs when readers may disagree on how pronouns should be interpreted. We describe a number of heuristics, each of which captures information that may lead a reader to favor a particular interpretation of the text. We use these heuristics to build a classifier, which in turn predicts the degree to which particular interpretations are preferred. We collected multiple human judgements on the interpretation of requirements exhibiting anaphoric ambiguity and showed how the distribution of these judgements can be used to assess whether a particular instance of ambiguity is nocuous. Given a requirements document written in natural language, our approach can identify sentences that contain anaphoric ambiguity, and use the classifier to alert the requirements writer of text that runs the risk of misinterpretation. We report on a series of experiments that we conducted to evaluate the performance of the automated system we developed to support our approach. The results show that the system achieves high recall with a consistent improvement on baseline precision subject to some ambiguity tolerance levels, allowing us to explore and highlight realistic and potentially problematic ambiguities in actual requirements documents.},
author = {Yang, Hui and de Roeck, Anne and Gervasi, Vincenzo and Willis, Alistair and Nuseibeh, Bashar},
doi = {10.1007/s00766-011-0119-y},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AnalysingAnaphoricAmbiguityInNaturalLanguageRequirements.pdf:pdf},
isbn = {0947-3602},
issn = {09473602},
journal = {Requirements Engineering},
keywords = {Anaphoric ambiguity,Antecedent preference heuristics,Human judgements,Machine learning,Natural language,Nocuous ambiguity,Noun-phrase coreference resolution,Requirements},
number = {3},
pages = {163--169},
title = {{Analysing anaphoric ambiguity in natural language requirements}},
volume = {16},
year = {2011}
}
@article{Wang2016,
author = {Wang, Yinglin},
doi = {10.1007/s12204-016-1783-3},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AutomaticSemanticAnalysisOfSoftwareRequirementsThroughMachineLearningAndOntologyApproach.pdf:pdf},
isbn = {1220401617},
issn = {19958188},
journal = {Journal of Shanghai Jiaotong University (Science)},
keywords = {machine learning,semantic role labelling,software requirement engineering},
number = {6},
pages = {692--701},
title = {{Automatic semantic analysis of software requirements through machine learning and ontology approach}},
volume = {21},
year = {2016}
}
@conference{Felbinger201623,
abstract = {Removing redundancies from test-suites is an important task of software testing in order to keep test-suites as small as possible, but not to harm the test-suite's fault detection capabilities. A straightforward algorithm for test-suite reduction would select elements of the test-suite randomly and remove them if and only if the reduced test-suite fulfills the same or similar coverage or mutation score. Such algorithms rely on the execution of the program and the repeated computation of coverage or mutation score. In this paper, we present an alternative approach that purely relies on a model learned from the original test-suite without requiring the execution of the program under test. The idea is to remove those tests that do not change the learned model. In order to evaluate the approach we carried out an experimental study showing that reductions of 60-99{\%} are possible while still keeping coverage and mutation score almost the same. {\textcopyright} 2016 IEEE.},
annote = {cited By 2},
author = {Felbinger, H and Wotawa, F and Nica, M},
booktitle = {Proceedings - 2016 IEEE International Conference on Software Quality, Reliability and Security-Companion, QRS-C 2016},
doi = {10.1109/QRS-C.2016.8},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/TestSuiteReductionDoesNotNecesarilyRequireExecutingTheProgramUnderTestpdf.pdf:pdf},
pages = {23--30},
title = {{Test-Suite Reduction Does Not Necessarily Require Executing the Program under Test}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84991824134{\&}doi=10.1109{\%}2FQRS-C.2016.8{\&}partnerID=40{\&}md5=839dcefdc601f5a940b43086be3655b9},
year = {2016}
}
@inproceedings{wohlin2014guidelines,
author = {Wohlin, Claes},
booktitle = {Proceedings of the 18th international conference on evaluation and assessment in software engineering},
organization = {ACM},
pages = {38},
title = {{Guidelines for snowballing in systematic literature studies and a replication in software engineering}},
year = {2014}
}
@inproceedings{giger2012can,
author = {Giger, Emanuel and Pinzger, Martin and Gall, Harald C},
booktitle = {Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/CanWePredictTypesOfCodeChagesAnEmpiralAnalysis.pdf:pdf},
organization = {IEEE},
pages = {217--226},
title = {{Can we predict types of code changes? an empirical analysis}},
year = {2012}
}
@inproceedings{AtasM.2018,
author = {{Atas M.} and {Samer R.} and {Felfernig A.}},
booktitle = {2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI)},
doi = {10.1109/WI.2018.00-10},
pages = {688--695},
publisher = {IEEE},
title = {{Automated Identification of Type-Specific Dependencies between Requirements}},
year = {2018}
}
@inproceedings{Li201725,
abstract = {Software requirement analysis is an essential step in software development process, which defines what is to be built in a project. Requirements are mostly written in text and will later evolve to fine-grained and actionable artifacts with details about system con-figurations, technology stacks, etc. Tracing the evolution of requirements enables stakeholders to determine the origin of each requirement and understand how well the software's design re-flects to its requirements. Reckoning requirements traceability is not a trivial task, we focus on applying machine learning approach to classify traceability between various associated requirements. In particular, we investigate a 2-learner, ontology-based approach, where we train two classifiers to separately exploit two types of features, lexical features and features derived from a hand-built ontology. In comparison to a supervised baseline system that uses only lexical features, our approach yields a relative error reduction of 25.9{\%}. Most interestingly, results do not deteriorate when the hand-built ontology is replaced with its automatically constructed counterpart. {\textcopyright} 2017 ACM.},
annote = {From Duplicate 2 (Tracing requirements in software design - Li, Z; Chen, M; Huang, L; Ng, V; Geng, R)

cited By 0},
author = {Li, Zeheng and Chen, Mingrui and Huang, LiGuo and Ng, Vincent and Geng, Ruili},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/3084100.3084102},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/TracingRequirementsInSoftwareDesign.pdf:pdf},
isbn = {9781450352703},
keywords = {2017,acm reference format,and ruili geng,liguo huang,machine learning,mingrui chen,requirements traceability,software design,vincent ng,zeheng li},
pages = {25--29},
title = {{Tracing requirements in software design}},
url = {http://dl.acm.org/citation.cfm?doid=3084100.3084102 https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025822995{\&}doi=10.1145{\%}2F3084100.3084102{\&}partnerID=40{\&}md5=3e0201f80b2e9286952334407867cdb1},
volume = {Part F1287},
year = {2017}
}
@article{mitchell1997machine,
author = {Mitchell, Tom M},
journal = {Burr Ridge, IL: McGraw Hill},
number = {37},
pages = {870--877},
title = {{Machine learning}},
volume = {45},
year = {1997}
}
@book{celebi2016unsupervised,
author = {Celebi, M Emre and Aydin, Kemal},
publisher = {Springer},
title = {{Unsupervised Learning Algorithms}},
year = {2016}
}
@article{lee2017machine,
abstract = {Machine learning (ML) has recently gained in popularity, spurred by well-publicized advances like deep learning and widespread commercial interest in big data analytics. Despite the enthusiasm, some renowned experts of the field have expressed skepticism, which is justifiable given the disappointment with the previous wave of neural networks and other AI techniques. On the other hand, new fundamental advances like the ability to train neural networks with a large number of layers for hierarchical feature learning may present significant new technological and commercial opportunities. This paper critically examines the main advances in deep learning. In addition, connections with another ML branch of reinforcement learning are elucidated and its role in control and decision problems is discussed. Implications of these advances for the fields of process and energy systems engineering are also discussed.},
author = {Lee, Jay H. and Shin, Joohyun and Realff, Matthew J.},
doi = {10.1016/j.compchemeng.2017.10.008},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/MachineLearningOverviewOfTheRecentProgressesAndImplicationsForTheProcessSystemsEngineeringField.pdf:pdf},
issn = {00981354},
journal = {Computers and Chemical Engineering},
keywords = {Deep learning,Machine learning,Process systems engineering,Reinforcement learning,Stochastic decision problems},
pages = {111--121},
publisher = {Elsevier},
title = {{Machine learning: Overview of the recent progresses and implications for the process systems engineering field}},
url = {http://dx.doi.org/10.1016/j.compchemeng.2017.10.008},
volume = {114},
year = {2018}
}
@article{Slankas2013a,
author = {Slankas, J and Williams, L},
doi = {10.1109/SocialCom.2013.68},
isbn = {9780769551371},
issn = {4673-3076},
journal = {Proceedings - SocialCom/PASSAT/BigData/EconCom/BioMedCom 2013},
keywords = {access control,documentation,explicitly grants,for example,hospital administrators to inactive,machine learning,natural language processing,patients,relation extraction,security,the system shall allow,within nature language},
pages = {435--440},
title = {{Access control policy extraction from unconstrained natural language text}},
url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-84893585590{\&}partnerID=40{\&}md5=3138f9c8565c51e9d7f9a6ce2149ff18},
year = {2013}
}
@article{Merten2016,
abstract = {Communication about requirements is often handled in issue tracking systems, especially in a distributed setting. As issue tracking systems also contain bug reports or programming tasks, the software feature requests of the users are often difficult to identify. This paper investigates natural language processing and machine learning features to detect software feature requests in natural language data of issue tracking systems. It compares traditional linguistic machine learning features, such as "bag of words", with more advanced features, such as subject-action-object, and evaluates combinations of machine learning features derived from the natural language and features taken from the issue tracking system meta-data. Our investigation shows that some combinations of machine learning features derived from natural language and the issue tracking system meta-data outperform traditional approaches. We show that issues or data fields (e.g. descriptions or comments), which contain software feature requests, can be identified reasonably well, but hardly the exact sentence. Finally, we show that the choice of machine learning algorithms should depend on the goal, e.g. maximization of the detection rate or balance between detection rate and precision. In addition, the paper contributes a double coded gold standard and an open-source implementation to further pursue this topic.},
archivePrefix = {arXiv},
arxivId = {arXiv:1508.06655v1},
author = {Merten, Thorsten and Falis, Mat{\'{u}}{\v{s}} and H{\"{u}}bner, Paul and Quirchmayr, Thomas and B{\"{u}}rsner, Simone and Paech, Barbara},
doi = {10.1109/RE.2016.8},
eprint = {arXiv:1508.06655v1},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/SoftwareFeatureRequestDetectionInIssueTrackingSystems.pdf:pdf},
isbn = {9781509041213},
issn = {02705257},
journal = {Proceedings - 2016 IEEE 24th International Requirements Engineering Conference, RE 2016},
keywords = {Machine Learning,Mining Software Repositories,Natural Language Processing,Software Feature Request Detection},
pages = {166--175},
pmid = {18268042},
title = {{Software Feature Request Detection in Issue Tracking Systems}},
year = {2016}
}
@inproceedings{winkler2016automatic,
abstract = {The results of the requirements engineering process are predominantly documented in natural language requirements specifications. Besides the actual requirements, these documents contain additional content such as explanations, summaries, and figures. For the later use of requirements specifications, it is important to be able to differentiate between legally relevant requirements and other auxiliary content. Therefore, one of our industry partners demands the requirements engineers to manually label each content element of a requirements specification as 'requirement' or 'information'. However, this manual labeling task is time-consuming and error-prone. In this paper, we present an approach to automatically classify content elements of a natural language requirements specification as 'requirement' or 'information'. Our approach uses convolutional neural networks. In an initial evaluation on a real-world automotive requirements specification, our approach was able to detect requirements with a precision of 0.73 and a recall of 0.89. The approach increases the quality of requirements specifications in the sense that it discriminates important content for following activities (e.g., which parts of the specification do I need to test?). {\textcopyright} 2016 IEEE.},
annote = {From Duplicate 2 (Automatic classification of requirements based on convolutional neural networks - Winkler, Jonas; Vogelsang, Andreas)

cited By 2},
author = {Winkler, Jonas and Vogelsang, Andreas},
booktitle = {Proceedings - 2016 IEEE 24th International Requirements Engineering Conference Workshops, REW 2016},
doi = {10.1109/REW.2016.16},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AutomaticClassificationOfRequirementsBasedOnConvolutionalNeuronalNetworks.pdf:pdf},
organization = {IEEE},
pages = {39--45},
title = {{Automatic classification of requirements based on convolutional neural networks}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013128187{\&}doi=10.1109{\%}2FREW.2016.16{\&}partnerID=40{\&}md5=8b58b3d8fcd3cbeeef2865518856e2bf},
year = {2016}
}
@book{zhang2006advances,
author = {Zhang, Du},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AdvancesMachineLearningApplicationsInSoftwareEngineering .pdf:pdf},
publisher = {IGI Global},
title = {{Advances in machine learning applications in software engineering}},
year = {2006}
}
@article{petersen2008systematic,
author = {Petersen, Kai and Feldt, Robert and Mujtaba, Shahid and Mattsson, Michael and Petersen},
doi = {10.1142/S0218194007003112},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/SystematicMappingStudiesInSoftwareEngineering.pdf:pdf},
isbn = {0-7695-2555-5},
issn = {02181940},
journal = {Proceedings of the 12th International Conference on Evaluation and Assessment in Software Engineering (EASE'08)},
keywords = {evidence based software engineering,systematic mapping studies,systematic reviews},
number = {June 2008},
pages = {68--77},
title = {{Systematic Mapping Studies in Software Engineering}},
url = {http://dl.acm.org/citation.cfm?id=2227115.2227123 http://robertfeldt.net/publications/petersen{\_}ease08{\_}sysmap{\_}studies{\_}in{\_}se.pdf},
volume = {8},
year = {2008}
}
@inproceedings{abad2017works,
author = {Abad, Zahra Shakeri Hossein and Karras, Oliver and Ghazi, Parisa and Glinz, Martin and Ruhe, Guenther and Schneider, Kurt},
booktitle = {Requirements Engineering Conference (RE), 2017 IEEE 25th International},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/WhatWorksBetterAStudyOfClassifyingRequirements.pdf:pdf},
organization = {IEEE},
pages = {496--501},
title = {{What works better? a study of classifying requirements}},
year = {2017}
}
@article{del2011requirement,
author = {del {\'{A}}guila, Isabel Mar{\'{i}}a and {Del Sagrado}, Jose},
doi = {10.1142/S0218194011005219},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/RequirementRiskLevelForecastUsingBayesianNetworksClassifiers.pdf:pdf},
issn = {0218-1940},
journal = {International Journal of Software Engineering and Knowledge Engineering},
keywords = {bayesian networks,data mining,requirement engineering,risk assessment},
number = {02},
pages = {167--190},
publisher = {World Scientific},
title = {{Requirement risk level forecast using Bayesian networks classifiers}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0218194011005219},
volume = {21},
year = {2011}
}
@article{Knauss201685,
abstract = {Context: Runtime uncertainty such as unpredictable operational environment and failure of sensors that gather environmental data is a well-known challenge for adaptive systems. Objective: To execute requirements that depend on context correctly, the system needs up-to-date knowledge about the context relevant to such requirements. Techniques to cope with uncertainty in contextual requirements are currently underrepresented. In this paper we present ACon (Adaptation of Contextual requirements), a data-mining approach to deal with runtime uncertainty affecting contextual requirements. Method: ACon uses feedback loops to maintain up-to-date knowledge about contextual requirements based on current context information in which contextual requirements are valid at runtime. Upon detecting that contextual requirements are affected by runtime uncertainty, ACon analyses and mines contextual data, to (re-)operationalize context and therefore update the information about contextual requirements. Results: We evaluate ACon in an empirical study of an activity scheduling system used by a crew of 4 rowers in a wild and unpredictable environment using a complex monitoring infrastructure. Our study focused on evaluating the data mining part of ACon and analysed the sensor data collected onboard from 46 sensors and 90,748 measurements per sensor. Conclusion: ACon is an important step in dealing with uncertainty affecting contextual requirements at runtime while considering end-user interaction. ACon supports systems in analysing the environment to adapt contextual requirements and complements existing requirements monitoring approaches by keeping the requirements monitoring specification up-to-date. Consequently, it avoids manual analysis that is usually costly in today's complex system environments. {\textcopyright} 2015 Elsevier B.V. All rights reserved.},
annote = {From Duplicate 1 (Acon: A learning-based approach to deal with uncertainty in contextual requirements at runtime - Knauss, A; Damian, D; Franch, X; Rook, A; M{\'{u}}ller, H A; Thomo, A)

cited By 7},
author = {Knauss, Alessia and Damian, Daniela and Franch, Xavier and Rook, Angela and M{\'{u}}ller, Hausi A. and Thomo, Alex},
doi = {10.1016/j.infsof.2015.10.001},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AConALearningBasedApproachToDealWithUncertaintyInContextualRequirementsAtRuntime.pdf:pdf},
issn = {09505849},
journal = {Information and Software Technology},
keywords = {Contextual requirements,Machine learning,Operationalization,Requirements engineering,Self-adaptive systems},
pages = {85--99},
title = {{Acon: A learning-based approach to deal with uncertainty in contextual requirements at runtime}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949443224{\&}doi=10.1016{\%}2Fj.infsof.2015.10.001{\&}partnerID=40{\&}md5=5386a36ceb20ab1b93fbb827e474b62a},
volume = {70},
year = {2016}
}
@conference{Abdukalykov2011158,
abstract = {The effort estimation techniques used in the software industry often tend to ignore the impact of Non-functional Requirements (NFR) on effort and reuse standard effort estimation models without local calibration. Moreover, the effort estimation models are calibrated using data of previous projects that may belong to problem domains different from the project which is being estimated. Our approach suggests a novel effort estimation methodology that can be used in the early stages of software development projects. Our proposed methodology initially clusters the historical data from the previous projects into different problem domains and generates domain specific effort estimation models, each incorporating the impact of NFR on effort by sets of objectively measured nominal features. We reduce the complexity of these models using a feature subset selection algorithm. In this paper, we discuss our approach in details, and we present the results of our experiments using different supervised machine learning algorithms. The results show that our approach performs well by increasing the correlation coefficient and decreasing the error rate of the generated effort estimation models and achieving more accurate effort estimates for the new projects. {\textcopyright} 2011 IEEE.},
annote = {cited By 4},
author = {Abdukalykov, R and Hussain, I and Kassab, M and Ormandjieva, O},
booktitle = {Proceedings - 2011 9th International Conference on Software Engineering Research, Management and Applications, SERA 2011},
doi = {10.1109/SERA.2011.45},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/QuantifyingTheImpactOfDifferentNonFunctionalRequirementsAndProblemDomainsOnSoftwareEffortEstimation.pdf:pdf},
pages = {158--165},
title = {{Quantifying the impact of different non-functional requirements and problem domains on software effort estimation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-82155161853{\&}doi=10.1109{\%}2FSERA.2011.45{\&}partnerID=40{\&}md5=c583d593b4135c50e5a726309fb8fc49},
year = {2011}
}
@inproceedings{nikora2009automated,
author = {Nikora, Allen P and Balcom, Galen},
booktitle = {Software Reliability Engineering, 2009. ISSRE'09. 20th International Symposium on},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AutomatedIdentificationOfLTLPatternsInNaturalLanguageRequirements.pdf:pdf},
organization = {IEEE},
pages = {185--194},
title = {{Automated identification of LTL patterns in natural language requirements}},
year = {2009}
}
@article{malhotra2017exploratory,
abstract = {Variation in software requirements, technological upgrade and occurrence of defects necessitate change in software for its effective use. Early detection of those classes of a software which are prone to change is critical for software developers and project managers as it can aid in efficient resource allocation of limited resources. Moreover, change prone classes should be efficiently restructured and designed to prevent introduction of defects. Recently, use of search based techniques and their hybridized counter-parts have been advocated in the field of software engineering predictive modeling as these techniques help in identification of optimal solutions for a specific problem by testing the goodness of a number of possible solutions. In this paper, we propose a novel approach for change prediction using search-based techniques and hybridized techniques. Further, we address the following issues: (i) low repeatability of empirical studies, (ii) less use of statistical tests for comparing the effectiveness of models, and (iii) non-assessment of trade-off between runtime and predictive performance of various techniques. This paper presents an empirical validation of search-based techniques and their hybridized versions, which yields unbi-ased, accurate and repeatable results. The study analyzes and compares the predictive performance of five search-based, five hybridized techniques and four widely used machine learning techniques and a statistical technique for predicting change prone classes in six application packages of a popular operating system for mobile—Android. 123 674 Autom Softw Eng (2017) 24:673–717 The results of the study advocate the use of hybridized techniques for developing mod-els to identify change prone classes.},
author = {Malhotra, Ruchika and Khanna, Megha},
doi = {10.1007/s10515-016-0203-0},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/AnExploratoryStudyForSoftwareChangePredictionInObjectOrientedSystemUsingHybridizedTechniques.pdf:pdf},
issn = {15737535},
journal = {Automated Software Engineering},
keywords = {Change proneness,Empirical validation,Hybridized techniques,Object-oriented metrics,Predictive modeling,Search-based techniques},
number = {3},
pages = {673--717},
publisher = {Springer US},
title = {{An exploratory study for software change prediction in object-oriented systems using hybridized techniques}},
volume = {24},
year = {2017}
}
@article{Asghar2010,
abstract = {Requirement Engineering acts as foundation for any software and is one of the most important tasks. Entire software is supported by four pillars of requirement engineering processes. Functional and non-functional requirements work as bricks to support software edifice. Finally, design, implementation and testing add stories to construct entire software tower on top of this foundation. Thus, the base needs to be well-built to support rest of software tower. For this purpose, requirement engineers come across with numerous challenges to develop successful software. The paper has highlighted requirement engineering challenges encountered in development of software applications and selection of right customer-off-the-shelf components (COTS). Comprehending stakeholder's needs; incomplete and inconsistent process description; verification and validation of requirements; classification and modeling of extensive data; selection of COTS product with minimum requirement modifications are foremost challenges faced during requirement engineering. Moreover, the paper has discussed and critically evaluated challenges highlighted by various researchers. Besides, the paper presents a model that encapsulates seven major challenges that recur during requirement engineering phase. These challenges have been further categorized into problems. Furthermore, the model has been linked with previous research work to elaborate challenges that have not been specified earlier. Anticipating requirement engineering challenges could assist requirement engineers to prevent software tower from any destruction.},
author = {Asghar, Sohail and Umar, Mahrukh},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/RequirementEngineeringChallengesInDevelopmentOfSoftwareApplicationsAnSelectionOfCustomerOffTheShelfComponents.pdf:pdf},
journal = {International Jounal of Software Engineering},
keywords = {Customer-off-the-shelf (COTS),Multi-site software development.,Requirement Engineering},
number = {2},
pages = {32--50},
title = {{Requirement Engineering Challenges in Development of Software Applications and Selection of Customer-off-the-Shelf (COTS)}},
url = {http://www.cscjournals.org/csc/manuscript/Journals/IJSE/volume1/Issue2/IJSE-7.pdf?origin=publication{\_}detail},
volume = {1},
year = {2010}
}
@inproceedings{gokyer2008non,
author = {Gokyer, Gokhan and Cetin, Semih and Sener, Cevat and Yondem, Meltem T},
booktitle = {Software Engineering Advances, 2008. ICSEA'08. The Third International Conference on},
file = {:C$\backslash$:/Users/guadalupe/Downloads/ArticulosdelaRevision/NonFunctionalRequirementsToArchitecturalConcernsMLAndNLPAtCrossroads.pdf:pdf},
organization = {IEEE},
pages = {400--406},
title = {{Non-functional requirements to architectural concerns: ML and NLP at crossroads}},
year = {2008}
}
@article{Catal2009,
author = {Catal, Cagatay and Diri, Banu},
journal = {Expert systems with applications},
number = {4},
pages = {7346--7354},
publisher = {Elsevier},
title = {{A systematic review of software fault prediction studies}},
volume = {36},
year = {2009}
}
@inproceedings{Hussain2007,
author = {Hussain, Ishrar and Ormandjieva, Olga and Kosseim, Leila},
booktitle = {Seventh International Conference on Quality Software (QSIC 2007)},
pages = {209--218},
title = {{Automatic quality assessment of SRS text by means of a decision-tree-based text classifier}},
year = {2007}
}
@inproceedings{Hayes2015,
author = {Hayes, Jane Huffman and Li, Wenbin and Yu, Tingting and Han, Xue and Hays, Mark and Woodson, Clinton},
booktitle = {2015 IEEE Second International Workshop on Artificial Intelligence for Requirements Engineering (AIRE)},
pages = {1--8},
title = {{Measuring Requirement Quality to Predict Testability}},
year = {2015}
}
@inproceedings{Ott2013,
author = {Ott, Daniel},
booktitle = {International Working Conference on Requirements Engineering: Foundation for Software Quality},
pages = {50--64},
title = {{Automatic requirement categorization of large natural language specifications at mercedes-benz for review improvements}},
year = {2013}
}
@book{Pohl2010,
author = {Pohl, Klaus},
publisher = {Springer Publishing Company, Incorporated},
title = {{Requirements engineering: fundamentals, principles, and techniques}},
year = {2010}
}
@article{Darnstadt2014,
author = {Darnst{\"{a}}dt, Malte and Simon, Hans Ulrich and Sz{\"{o}}r{\'{e}}nyi, Bal{\'{a}}zs},
journal = {Theoretical Computer Science},
pages = {68--87},
publisher = {Elsevier},
title = {{Supervised learning and co-training}},
volume = {519},
year = {2014}
}
@book{Knox2018,
author = {Knox, Steven W},
publisher = {John Wiley {\&} Sons},
title = {{Machine learning: a concise introduction}},
volume = {285},
year = {2018}
}
